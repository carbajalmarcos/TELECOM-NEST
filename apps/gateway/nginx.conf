user nginx;
worker_processes auto;

error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
	#
	# Determines how many clients will be served by each worker process.
	# (Max clients = worker_connections * worker_processes)
	# Should be equal to `ulimit -n`
	#
	worker_connections  4096;

	#
	# Allow nginx to handling accepting more than 1 connection at a time.
	# Our AWS ELBs use persistent L4 TCP connections, as requests increase
	# so does the number of persistent connections that are opened. We should
	# be able to handle this increase in connections by accepting them in bulk.
	#
	multi_accept on;
}


http {
	include /etc/nginx/mime.types;
	default_type application/octet-stream;

	log_format main '$remote_addr - $remote_user [$time_local] "$request" '
				  '$status $body_bytes_sent "$http_referer" '
					'"$http_user_agent" "$http_x_forwarded_for"';

	access_log /var/log/nginx/access.log main;

    # https://thoughts.t37.net/nginx-optimization-understanding-sendfile-tcp-nodelay-and-tcp-nopush-c55cdd276765
	sendfile on;
	tcp_nopush on;
    tcp_nodelay on;

	keepalive_timeout 65;

	##
	# Gzip Settings
	##
	gzip on;
	gzip_disable "msie6";
	# gzip_vary on;
	# gzip_proxied any;
	# gzip_comp_level 6;
	# gzip_buffers 16 8k;
	# gzip_http_version 1.1;
	gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

	include /etc/nginx/conf.d/*.conf;
}